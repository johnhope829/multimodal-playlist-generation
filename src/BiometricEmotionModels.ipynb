{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab83164-b2db-4d7b-9d4a-8b4c63876feb",
   "metadata": {},
   "source": [
    "# Detecting Stress/Emotion Signals from Biometric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9012ae-59dd-418d-96be-20801a763afc",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89cb5a32-e7f8-492a-9b5d-06537076674a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7cd6d-24e7-4b48-9aa7-f6a8598f0198",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8e9e1-9f8e-4a21-8173-549117facc48",
   "metadata": {},
   "source": [
    "The WESAD dataset is a multimodal dataset for wearable stress and affect detection, collected from 15 subjects using two devices: a chest-worn RespiBAN and a wrist-worn Empatica E4. It includes synchronized physiological signals such as EDA, ECG, EMG, respiration, temperature, and acceleration, sampled at high resolution. Each subject underwent conditions like baseline, stress, and amusement, with corresponding labels provided in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e65e4a-8922-4ba1-889e-75e446251ce7",
   "metadata": {},
   "source": [
    "### Loading Signals and Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508b2bb-3866-43c0-8c71-ecb6b6f40e4a",
   "metadata": {},
   "source": [
    "#### Downsampling, windowing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a42cf3a-1db8-4428-a156-a5a46ac30f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLING_RATE_ORIG = 700\n",
    "SAMPLING_RATE_TARGET = 4\n",
    "WINDOW_SIZE_SEC = 15\n",
    "STRIDE_SEC = 5\n",
    "\n",
    "# Maps canonical names to actual keys in the dataset\n",
    "SIGNAL_MAP = {\n",
    "    'EDA': {'chest': 'EDA',   'wrist': 'EDA'},\n",
    "    'TEMP': {'chest': 'Temp', 'wrist': 'TEMP'},\n",
    "    'RESP': {'chest': 'Resp', 'wrist': None},   # Not available on wrist\n",
    "    'ECG': {'chest': 'ECG',   'wrist': None},   # Not available on wrist\n",
    "    'ACC': {'chest': 'ACC',   'wrist': 'ACC'},\n",
    "    'EMG': {'chest': 'EMG',   'wrist': None},\n",
    "    'BVP': {'chest': None,    'wrist': 'BVP'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addf57f2-1d26-4f4e-b4f2-2295e7e4fb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_downsample(subject_path, signals, device='chest'):\n",
    "    with open(subject_path, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "    label = data['label']\n",
    "    scale = SAMPLING_RATE_TARGET / SAMPLING_RATE_ORIG\n",
    "    new_len = int(len(label) * scale)\n",
    "\n",
    "    signal_list = []\n",
    "\n",
    "    for sig in signals:\n",
    "        sig_key = SIGNAL_MAP[sig]\n",
    "        parts = []\n",
    "\n",
    "        for part in ['chest', 'wrist']:\n",
    "            if device in [part, 'both'] and sig_key[part]:\n",
    "                source = data['signal'][part][sig_key[part]]\n",
    "                if source.ndim == 1:\n",
    "                    source = source[:, np.newaxis]\n",
    "                s_down = resample(source, new_len, axis=0)\n",
    "                parts.append(s_down)\n",
    "\n",
    "        if parts:\n",
    "            signal_list.append(np.concatenate(parts, axis=1))\n",
    "\n",
    "    all_signals = np.concatenate(signal_list, axis=1)\n",
    "    labels = resample(label.astype(float), new_len).round().astype(int)\n",
    "    return all_signals, labels\n",
    "\n",
    "def normalize(data):\n",
    "    return StandardScaler().fit_transform(data)\n",
    "\n",
    "def create_windows(X, y, window_size=WINDOW_SIZE_SEC * SAMPLING_RATE_TARGET, stride=STRIDE_SEC * SAMPLING_RATE_TARGET):\n",
    "    windows, labels = [], []\n",
    "    for i in range(0, len(X) - window_size, stride):\n",
    "        win_x = X[i:i + window_size]\n",
    "        win_y = y[i:i + window_size]\n",
    "        if np.any(win_y == 0):\n",
    "            continue\n",
    "        majority_label = np.bincount(win_y).argmax()\n",
    "        windows.append(win_x)\n",
    "        labels.append(majority_label)\n",
    "    return np.array(windows), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6bc1bd-c43f-4c47-83c9-5743343a4964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PANAS_ITEMS = [\n",
    "    'Active', 'Distressed', 'Interested', 'Inspired', 'Annoyed', 'Strong', 'Guilty',\n",
    "    'Scared', 'Hostile', 'Excited', 'Proud', 'Irritable', 'Enthusiastic', 'Ashamed',\n",
    "    'Alert', 'Nervous', 'Determined', 'Attentive', 'Jittery', 'Afraid', 'Stressed',\n",
    "    'Frustrated', 'Happy', 'Angry', 'Irritated', 'Sad'\n",
    "]\n",
    "\n",
    "TARGET_PANAS = ['Stressed', 'Angry', 'Happy', 'Sad', 'Inspired', 'Excited', 'Nervous']  # you can modify this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df3006b-8886-4726-9ed5-a562cd213d50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_panas_scores(quest_path):\n",
    "    condition_scores = []\n",
    "\n",
    "    with open(quest_path, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=';')\n",
    "        rows = [r for r in reader if r and r[0].startswith('# PANAS')]\n",
    "\n",
    "    for row in rows:\n",
    "        try:\n",
    "            # Clean and parse only non-empty fields\n",
    "            scores = [int(val) for val in row[1:] if val.strip().isdigit()]\n",
    "            if len(scores) < len(PANAS_ITEMS):\n",
    "                continue\n",
    "            condition_scores.append(dict(zip(PANAS_ITEMS, scores)))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse PANAS in {quest_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return condition_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee98013-802c-40c3-a9a7-b4783d2d9bbe",
   "metadata": {},
   "source": [
    "#### Loading to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0827ab4-5bf4-406d-922a-5f88fa5d1fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_wesad_dataset(root_path, selected_signals=('EDA', 'TEMP', 'RESP', 'ECG', 'ACC'), device='chest'):\n",
    "    all_x, all_y_cls, all_y_reg, all_subject_ids = [], [], [], []\n",
    "\n",
    "    for subject_dir in sorted(os.listdir(root_path)):\n",
    "\n",
    "        if not subject_dir.startswith(\"S\"):\n",
    "            continue\n",
    "\n",
    "        pkl_path = os.path.join(root_path, subject_dir, f\"{subject_dir}.pkl\")\n",
    "        quest_path = os.path.join(root_path, subject_dir, f\"{subject_dir}_quest.csv\")\n",
    "\n",
    "        if not os.path.exists(pkl_path) or not os.path.exists(quest_path):\n",
    "            print(f\"Skipping {subject_dir}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            X, y = load_and_downsample(pkl_path, selected_signals, device)\n",
    "            X = normalize(X)\n",
    "            win_x, win_y = create_windows(X, y)\n",
    "\n",
    "            # === Load PANAS Scores ===\n",
    "            panas_per_condition = extract_panas_scores(quest_path)\n",
    "            y_reg = []\n",
    "\n",
    "            for label in win_y:\n",
    "                condition_idx = label - 1  # 1=Base, 2=Stress, ...\n",
    "                if condition_idx >= len(panas_per_condition):\n",
    "                    y_reg.append([0.0] * len(TARGET_PANAS))  # fallback\n",
    "                    continue\n",
    "\n",
    "                score_vec = [panas_per_condition[condition_idx][key] for key in TARGET_PANAS]\n",
    "                y_reg.append(score_vec)\n",
    "\n",
    "            all_x.append(win_x)\n",
    "            all_y_cls.append(win_y)\n",
    "            all_y_reg.append(np.array(y_reg))\n",
    "            \n",
    "            subject_ids = [subject_dir] * len(win_x)  # same ID for all windows from this subject\n",
    "            all_subject_ids.append(np.array(subject_ids))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {subject_dir}: {e}\")\n",
    "    \n",
    "    return (\n",
    "        np.concatenate(all_x),\n",
    "        np.concatenate(all_y_cls),\n",
    "        np.concatenate(all_y_reg),\n",
    "        np.concatenate(all_subject_ids)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d3d1b-8af0-4287-a28f-3ff33d29705f",
   "metadata": {},
   "source": [
    "#### Define class for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb27a13-603a-4430-9172-d2abd3cc5f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WESADDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0381b16-d7cb-4940-8162-163bd48fca7b",
   "metadata": {},
   "source": [
    "#### Load and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd8cfdf8-d98e-4a92-9828-fcb4ceec53c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (9120, 60, 12)\n",
      "Classification labels: (9120,)\n",
      "PANAS regression targets: (9120, 7)\n"
     ]
    }
   ],
   "source": [
    "X, y_cls, y_reg, subject_ids = load_wesad_dataset(\n",
    "    root_path=\"../data/WESAD\",\n",
    "    selected_signals=('EDA', 'TEMP', 'RESP', 'ECG', 'ACC'),\n",
    "    device='both'\n",
    ")\n",
    "\n",
    "print(\"Features:\", X.shape)\n",
    "print(\"Classification labels:\", y_cls.shape)\n",
    "print(\"PANAS regression targets:\", y_reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7508c762-180e-491d-9e27-412154adf9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save for later regression task\n",
    "X_reg = X\n",
    "subject_ids_reg = subject_ids\n",
    "\n",
    "# Define mask\n",
    "valid_mask = (y_cls >= 1) & (y_cls <= 4)\n",
    "\n",
    "# Apply masking\n",
    "X = X[valid_mask]\n",
    "y_cls = y_cls[valid_mask] - 1\n",
    "\n",
    "subject_ids = np.array(subject_ids)[valid_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088f698-d7c5-4c48-b775-c30de30d40d9",
   "metadata": {},
   "source": [
    "## Modeling - Condition Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d34fd2-a9a7-4b1e-9d57-e72c3a4f47c8",
   "metadata": {},
   "source": [
    "### Split and Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d07d7fd-ace4-41bc-8ab8-db6b18be4af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unique subjects\n",
    "unique_subjects = sorted(set(subject_ids))\n",
    "train_subjects, val_subjects = train_test_split(unique_subjects, test_size=0.2, random_state=42)\n",
    "\n",
    "# Subject-level masks\n",
    "train_mask = np.isin(subject_ids, train_subjects)\n",
    "val_mask = np.isin(subject_ids, val_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7813beb0-396c-4876-b588-5bc6fe1c0c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_cls_train = X[train_mask], y_cls[train_mask]\n",
    "X_val,   y_cls_val   = X[val_mask],   y_cls[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac4ed16-7829-45ab-8818-29460d003290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WESADClassificationDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = WESADClassificationDataset(X_train, y_cls_train)\n",
    "val_ds   = WESADClassificationDataset(X_val, y_cls_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af54fde-7490-479e-aaf3-bc27a129e8bf",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35e9cfa0-816e-4671-a6ae-aeac57d9ddb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNEmotionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=12, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, 12, 60)\n",
    "        x = self.net(x)\n",
    "        x = x.squeeze(-1)       # (B, 256)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34acd7d0-45ff-41aa-8025-15261afd24a5",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e16fef4-618b-4b5f-a730-c4bbe528cf41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels:\", np.unique(y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cd91b2a-eb5a-49cf-ad10-f6699523fe7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b695d01-0bfe-40ab-8e3d-1dbe3b64b39f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CNNEmotionClassifier(input_dim=12, num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e821497f-9cec-4e99-9c40-25508066094c",
   "metadata": {},
   "source": [
    "### Set Up Training / Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8a55b77-2be3-45a0-a3ef-0f141488afa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e3dfad2-ee75-4cda-93a3-72f17994a177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f0a92-58a5-4896-9ac7-5d65f582522b",
   "metadata": {},
   "source": [
    "### Run Training / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13037593-b527-41b3-ab56-1ae4bc410dca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.3137 | Acc: 0.8947 | Val Loss: 0.8289 | Acc: 0.7955\n",
      "Epoch 02 | Train Loss: 0.0646 | Acc: 0.9826 | Val Loss: 1.0672 | Acc: 0.7994\n",
      "Epoch 03 | Train Loss: 0.0310 | Acc: 0.9922 | Val Loss: 1.0234 | Acc: 0.8040\n",
      "Epoch 04 | Train Loss: 0.0226 | Acc: 0.9942 | Val Loss: 0.9121 | Acc: 0.7994\n",
      "Epoch 05 | Train Loss: 0.0162 | Acc: 0.9953 | Val Loss: 0.8207 | Acc: 0.8466\n",
      "Epoch 06 | Train Loss: 0.0124 | Acc: 0.9963 | Val Loss: 1.2622 | Acc: 0.8074\n",
      "Epoch 07 | Train Loss: 0.0063 | Acc: 0.9990 | Val Loss: 1.1858 | Acc: 0.7869\n",
      "Epoch 08 | Train Loss: 0.0051 | Acc: 0.9984 | Val Loss: 1.1133 | Acc: 0.8091\n",
      "Epoch 09 | Train Loss: 0.0023 | Acc: 0.9994 | Val Loss: 1.1484 | Acc: 0.8102\n",
      "Epoch 10 | Train Loss: 0.0071 | Acc: 0.9981 | Val Loss: 1.7754 | Acc: 0.7824\n",
      "Epoch 11 | Train Loss: 0.0104 | Acc: 0.9979 | Val Loss: 1.3348 | Acc: 0.8239\n",
      "Epoch 12 | Train Loss: 0.0088 | Acc: 0.9979 | Val Loss: 1.0663 | Acc: 0.8551\n",
      "Epoch 13 | Train Loss: 0.0012 | Acc: 0.9999 | Val Loss: 1.0458 | Acc: 0.8222\n",
      "Epoch 14 | Train Loss: 0.0010 | Acc: 0.9997 | Val Loss: 1.0227 | Acc: 0.8375\n",
      "Epoch 15 | Train Loss: 0.0004 | Acc: 1.0000 | Val Loss: 0.9959 | Acc: 0.8545\n",
      "Epoch 16 | Train Loss: 0.0004 | Acc: 1.0000 | Val Loss: 1.0080 | Acc: 0.8426\n",
      "Epoch 17 | Train Loss: 0.0003 | Acc: 1.0000 | Val Loss: 1.0062 | Acc: 0.8483\n",
      "Epoch 18 | Train Loss: 0.0002 | Acc: 1.0000 | Val Loss: 1.0124 | Acc: 0.8483\n",
      "Epoch 19 | Train Loss: 0.0002 | Acc: 1.0000 | Val Loss: 0.9898 | Acc: 0.8392\n",
      "Epoch 20 | Train Loss: 0.0003 | Acc: 1.0000 | Val Loss: 0.9960 | Acc: 0.8540\n",
      "Epoch 21 | Train Loss: 0.0004 | Acc: 1.0000 | Val Loss: 1.1496 | Acc: 0.8170\n",
      "Epoch 22 | Train Loss: 0.0005 | Acc: 1.0000 | Val Loss: 1.0372 | Acc: 0.8591\n",
      "Epoch 23 | Train Loss: 0.0025 | Acc: 0.9990 | Val Loss: 1.0438 | Acc: 0.8273\n",
      "Epoch 24 | Train Loss: 0.0313 | Acc: 0.9920 | Val Loss: 1.3900 | Acc: 0.8006\n",
      "Epoch 25 | Train Loss: 0.0128 | Acc: 0.9966 | Val Loss: 1.6482 | Acc: 0.7750\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 26):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb4c7daf-2dd6-47ee-b019-f379ae67486f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_emotion_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92da5a3-19c2-4bcd-8712-898fe0640b28",
   "metadata": {},
   "source": [
    "## Modeling - Emotion Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efbcb4e-ec1d-4a50-bc2c-e4b11551fdd7",
   "metadata": {},
   "source": [
    "### Split and Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3696017-7d66-477f-8056-49b43688dd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WESADRegressionDataset(Dataset):\n",
    "    def __init__(self, X, y_reg):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y_reg, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe02b2e8-6835-4485-8915-3f382c2dcf06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Include subject ids\n",
    "subject_ids = np.array(subject_ids_reg)\n",
    "\n",
    "# Normalize score\n",
    "y_reg = (y_reg - 1) / 4.0\n",
    "\n",
    "train_mask = np.isin(subject_ids, train_subjects)\n",
    "val_mask   = np.isin(subject_ids, val_subjects)\n",
    "\n",
    "X_train, y_reg_train = X_reg[train_mask], y_reg[train_mask]\n",
    "X_val,   y_reg_val   = X_reg[val_mask],   y_reg[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dc3cd6c-b7a0-4e25-a342-27da2cad31c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = WESADRegressionDataset(X_train, y_reg_train)\n",
    "val_ds   = WESADRegressionDataset(X_val,   y_reg_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18bf6df-a443-4738-a09d-f961240a304c",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87d68c10-8e9b-4efb-a462-574924b01252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PANASRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=12, output_dim=7):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.regressor = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)     # (B, 12, 60)\n",
    "        x = self.encoder(x)        # (B, 256, 1)\n",
    "        x = x.squeeze(-1)          # (B, 256)\n",
    "        return self.regressor(x)   # (B, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e2bafdc-b9b6-4409-865d-a2af0cadfd67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PANASRegressor(input_dim=12, output_dim=7).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c24677-5b31-42c9-8dfd-97c0e0d6e924",
   "metadata": {},
   "source": [
    "### Set Up Training / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82251fc3-39ec-4707-bb28-76810d4633a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_regression(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed654332-2e16-49df-91f6-a0ec16f27a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_regression(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_targets, all_inputs = [], [], []\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "\n",
    "        loss = criterion(pred, y)\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "\n",
    "        all_inputs.append(X.cpu().numpy())\n",
    "        all_preds.append(pred.cpu().numpy())\n",
    "        all_targets.append(y.cpu().numpy())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_inputs = np.concatenate(all_inputs)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    # Prepare columns\n",
    "    x_vecs = [x.flatten() for x in all_inputs]\n",
    "    pred_vecs = [x.flatten() for x in all_preds]\n",
    "\n",
    "    # === PANAS emotions ===\n",
    "    panas_emotions = ['Stressed', 'Angry', 'Happy', 'Sad', 'Inspired', 'Excited', 'Nervous']\n",
    "\n",
    "    # Extract top moods from predictions\n",
    "    def extract_top_moods(pred_vec, top_n=3):\n",
    "        indices = np.argsort(pred_vec)[-top_n:][::-1]\n",
    "        return [(panas_emotions[i], round(pred_vec[i], 4)) for i in indices]\n",
    "\n",
    "    top_moods = [extract_top_moods(vec) for vec in pred_vecs]\n",
    "\n",
    "    # Build final DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"x_vec\": x_vecs,\n",
    "        \"pred\": pred_vecs,\n",
    "        \"top_moods\": top_moods,\n",
    "        \"mood_1\": [m[0][0] for m in top_moods],\n",
    "        \"mood_1_score\": [m[0][1] for m in top_moods],\n",
    "        \"mood_2\": [m[1][0] for m in top_moods],\n",
    "        \"mood_2_score\": [m[1][1] for m in top_moods],\n",
    "        \"mood_3\": [m[2][0] for m in top_moods],\n",
    "        \"mood_3_score\": [m[2][1] for m in top_moods],\n",
    "    })\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(all_targets, all_preds)\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    pearsons = [pearsonr(all_preds[:, i], all_targets[:, i])[0] for i in range(all_targets.shape[1])]\n",
    "\n",
    "    return total_loss / len(loader.dataset), mse, mae, pearsons, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a73696-51ef-42b0-8206-49306b4c94d6",
   "metadata": {},
   "source": [
    "### Run Training / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "451a3460-85e2-4a2d-aa40-550b1f0b1bac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.0000 | Val Loss: 0.0045 | MSE: 0.0045 | MAE: 0.0359 | Pearson r: ['0.766', '0.800', '0.674', '0.838', '0.748', '0.695', '0.823']\n",
      "Epoch 02 | Train Loss: 0.0001 | Val Loss: 0.0038 | MSE: 0.0038 | MAE: 0.0379 | Pearson r: ['0.787', '0.844', '0.645', '0.856', '0.655', '0.705', '0.829']\n",
      "Epoch 03 | Train Loss: 0.0002 | Val Loss: 0.0044 | MSE: 0.0044 | MAE: 0.0369 | Pearson r: ['0.637', '0.786', '0.785', '0.714', '0.810', '0.616', '0.730']\n",
      "Epoch 04 | Train Loss: 0.0000 | Val Loss: 0.0046 | MSE: 0.0046 | MAE: 0.0380 | Pearson r: ['0.748', '0.754', '0.663', '0.795', '0.748', '0.660', '0.795']\n",
      "Epoch 05 | Train Loss: 0.0000 | Val Loss: 0.0051 | MSE: 0.0051 | MAE: 0.0401 | Pearson r: ['0.680', '0.754', '0.623', '0.761', '0.719', '0.632', '0.754']\n",
      "Epoch 06 | Train Loss: 0.0000 | Val Loss: 0.0047 | MSE: 0.0047 | MAE: 0.0388 | Pearson r: ['0.722', '0.813', '0.614', '0.795', '0.719', '0.673', '0.789']\n",
      "Epoch 07 | Train Loss: 0.0000 | Val Loss: 0.0049 | MSE: 0.0049 | MAE: 0.0390 | Pearson r: ['0.712', '0.793', '0.625', '0.784', '0.727', '0.665', '0.780']\n",
      "Epoch 08 | Train Loss: 0.0000 | Val Loss: 0.0047 | MSE: 0.0047 | MAE: 0.0382 | Pearson r: ['0.731', '0.824', '0.629', '0.795', '0.734', '0.680', '0.797']\n",
      "Epoch 09 | Train Loss: 0.0000 | Val Loss: 0.0046 | MSE: 0.0046 | MAE: 0.0380 | Pearson r: ['0.724', '0.822', '0.645', '0.800', '0.747', '0.684', '0.791']\n",
      "Epoch 10 | Train Loss: 0.0000 | Val Loss: 0.0045 | MSE: 0.0045 | MAE: 0.0372 | Pearson r: ['0.743', '0.837', '0.649', '0.814', '0.756', '0.698', '0.808']\n",
      "Epoch 11 | Train Loss: 0.0000 | Val Loss: 0.0045 | MSE: 0.0045 | MAE: 0.0371 | Pearson r: ['0.736', '0.828', '0.655', '0.807', '0.755', '0.691', '0.801']\n",
      "Epoch 12 | Train Loss: 0.0000 | Val Loss: 0.0043 | MSE: 0.0043 | MAE: 0.0363 | Pearson r: ['0.758', '0.848', '0.663', '0.825', '0.767', '0.711', '0.821']\n",
      "Epoch 13 | Train Loss: 0.0000 | Val Loss: 0.0044 | MSE: 0.0044 | MAE: 0.0362 | Pearson r: ['0.745', '0.839', '0.664', '0.821', '0.767', '0.708', '0.811']\n",
      "Epoch 14 | Train Loss: 0.0000 | Val Loss: 0.0044 | MSE: 0.0044 | MAE: 0.0361 | Pearson r: ['0.758', '0.845', '0.656', '0.825', '0.764', '0.714', '0.820']\n",
      "Epoch 15 | Train Loss: 0.0000 | Val Loss: 0.0043 | MSE: 0.0043 | MAE: 0.0360 | Pearson r: ['0.756', '0.844', '0.666', '0.824', '0.769', '0.713', '0.819']\n",
      "Epoch 16 | Train Loss: 0.0000 | Val Loss: 0.0044 | MSE: 0.0044 | MAE: 0.0361 | Pearson r: ['0.748', '0.838', '0.675', '0.824', '0.774', '0.709', '0.813']\n",
      "Epoch 17 | Train Loss: 0.0000 | Val Loss: 0.0042 | MSE: 0.0042 | MAE: 0.0356 | Pearson r: ['0.761', '0.854', '0.665', '0.832', '0.772', '0.720', '0.826']\n",
      "Epoch 18 | Train Loss: 0.0000 | Val Loss: 0.0043 | MSE: 0.0043 | MAE: 0.0356 | Pearson r: ['0.751', '0.846', '0.664', '0.825', '0.770', '0.716', '0.817']\n",
      "Epoch 19 | Train Loss: 0.0000 | Val Loss: 0.0044 | MSE: 0.0044 | MAE: 0.0358 | Pearson r: ['0.749', '0.835', '0.664', '0.827', '0.770', '0.712', '0.815']\n",
      "Epoch 20 | Train Loss: 0.0000 | Val Loss: 0.0043 | MSE: 0.0043 | MAE: 0.0358 | Pearson r: ['0.761', '0.847', '0.663', '0.831', '0.767', '0.720', '0.824']\n",
      "Epoch 21 | Train Loss: 0.0000 | Val Loss: 0.0044 | MSE: 0.0044 | MAE: 0.0359 | Pearson r: ['0.748', '0.846', '0.661', '0.826', '0.766', '0.713', '0.814']\n",
      "Epoch 22 | Train Loss: 0.0000 | Val Loss: 0.0044 | MSE: 0.0044 | MAE: 0.0360 | Pearson r: ['0.752', '0.845', '0.655', '0.826', '0.763', '0.709', '0.817']\n",
      "Epoch 23 | Train Loss: 0.0000 | Val Loss: 0.0045 | MSE: 0.0045 | MAE: 0.0364 | Pearson r: ['0.750', '0.835', '0.643', '0.824', '0.753', '0.707', '0.813']\n",
      "Epoch 24 | Train Loss: 0.0000 | Val Loss: 0.0045 | MSE: 0.0045 | MAE: 0.0368 | Pearson r: ['0.746', '0.828', '0.650', '0.821', '0.756', '0.702', '0.809']\n",
      "Epoch 25 | Train Loss: 0.0000 | Val Loss: 0.0043 | MSE: 0.0043 | MAE: 0.0355 | Pearson r: ['0.753', '0.843', '0.659', '0.833', '0.764', '0.718', '0.819']\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 26):\n",
    "    train_loss = train_regression(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_mse, val_mae, val_corr, pred_df = evaluate_regression(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | MSE: {val_mse:.4f} | MAE: {val_mae:.4f} | \"\n",
    "          f\"Pearson r: {['%.3f' % r for r in val_corr]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41f64d43-5b56-404d-93f9-6784e116cd46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Emotion Pearson Correlation (sorted):\n",
      "Angry      | r = 0.843\n",
      "Sad        | r = 0.833\n",
      "Nervous    | r = 0.819\n",
      "Inspired   | r = 0.764\n",
      "Stressed   | r = 0.753\n",
      "Excited    | r = 0.718\n",
      "Happy      | r = 0.659\n"
     ]
    }
   ],
   "source": [
    "# Pair names with r values\n",
    "emotion_r = list(zip(TARGET_PANAS, val_corr))\n",
    "\n",
    "# Sort descending by correlation\n",
    "emotion_r_sorted = sorted(emotion_r, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Per-Emotion Pearson Correlation (sorted):\")\n",
    "for name, r in emotion_r_sorted:\n",
    "    print(f\"{name:10s} | r = {r:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07378e06-c62a-42dd-8265-6738f052e80b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_emotion_regressor.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "579ea07d-c9fd-48d0-8eaa-79a8bb1e3f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv('Biometric_Preds.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2acbdc6d-e56e-4381-9453-b61640670a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.764921  , -0.4475805 , -0.82929504,  0.5212836 ,  0.50040215,\n",
       "       -0.92199504, -0.36001477,  0.44702625, -0.87836605, -0.01312813,\n",
       "        0.6364317 ,  1.2824786 , -0.7653725 , -0.43644914, -0.83486634,\n",
       "        0.5212836 ,  0.48305476,  1.3990307 , -0.3486122 ,  0.46409488,\n",
       "       -0.8671883 , -0.01120681,  0.6335896 ,  1.2833139 , -0.7630118 ,\n",
       "       -0.4457255 , -0.8287748 ,  0.5566924 ,  0.26409566,  0.8168606 ,\n",
       "       -0.32449073,  0.46885985, -0.8543507 , -0.01298389,  0.6354041 ,\n",
       "        1.2824144 , -0.7635935 , -0.4327377 , -0.83064765,  0.5566924 ,\n",
       "        0.07390724, -0.61315817, -0.3058746 ,  0.4831434 , -0.84214777,\n",
       "       -0.0113356 ,  0.6341799 ,  1.2834722 , -0.76508826, -0.43644914,\n",
       "       -0.8332962 ,  0.5566924 , -0.1570733 , -0.21044455, -0.30179775,\n",
       "        0.4825566 , -0.83459693, -0.01287169,  0.6350271 ,  1.2820122 ,\n",
       "       -0.76225907, -0.43459415, -0.831026  ,  0.5566924 , -0.36315736,\n",
       "        1.2195939 , -0.282875  ,  0.49737942, -0.82534254, -0.01143299,\n",
       "        0.6344376 ,  1.2853049 , -0.7632816 , -0.43830413, -0.8289451 ,\n",
       "        0.5566924 , -0.46463734, -0.0205511 , -0.2737295 ,  0.48782387,\n",
       "       -0.8265935 , -0.01278683,  0.6348422 ,  1.2851627 , -0.7642213 ,\n",
       "       -0.43644914, -0.8312436 ,  0.5566924 , -0.5003553 , -1.2864736 ,\n",
       "       -0.28999382,  0.48265865, -0.8342068 , -0.01150741,  0.6345751 ,\n",
       "        1.2821583 , -0.76372945, -0.43830413, -0.8288599 ,  0.5566924 ,\n",
       "       -0.43910837, -0.9961986 , -0.3163588 ,  0.47503182, -0.8417756 ,\n",
       "       -0.01272109,  0.63473696,  1.2833184 , -0.7631231 , -0.43644914,\n",
       "       -0.82873696,  0.5566924 , -0.15520726,  1.0635418 , -0.31992677,\n",
       "        0.47113976, -0.8479707 , -0.01156592,  0.63465756,  1.2825804 ,\n",
       "       -0.7631896 , -0.43644914, -0.8324638 ,  0.4858748 ,  0.16831672,\n",
       "        0.12774856, -0.32475242,  0.451971  , -0.8447685 , -0.01266865,\n",
       "        0.6346712 ,  1.2831311 , -0.76419383, -0.43830413, -0.8308274 ,\n",
       "        0.4858748 ,  0.41650423, -0.9106962 , -0.32107547,  0.46452886,\n",
       "       -0.84665823, -0.01161325,  0.6347108 ,  1.2826835 , -0.76489836,\n",
       "       -0.43830413, -0.83286107,  0.4858748 ,  0.48559743,  0.11978725,\n",
       "       -0.3167444 ,  0.47125322, -0.8438821 , -0.01262566,  0.6346275 ,\n",
       "        1.2830676 , -0.7640309 , -0.43644914, -0.82457507,  0.4858748 ,\n",
       "        0.34952724,  1.5820255 , -0.2909321 ,  0.4916267 , -0.83218807,\n",
       "       -0.01165254,  0.6390887 ,  1.2827256 , -0.763925  , -0.43644914,\n",
       "       -0.8327759 ,  0.5212836 ,  0.0854583 ,  0.0244104 , -0.28020257,\n",
       "        0.48171565, -0.8208201 , -0.01258954,  0.63459706,  1.2830383 ,\n",
       "       -0.7635827 , -0.43644914, -0.8260601 ,  0.5212836 , -0.13261063,\n",
       "       -0.77470523, -0.2776807 ,  0.4882895 , -0.8183782 , -0.01168592,\n",
       "        0.63477284,  1.282747  , -0.7627379 , -0.43644914, -0.8319719 ,\n",
       "        0.5212836 , -0.34273595, -0.0588588 , -0.2753222 ,  0.48811015,\n",
       "       -0.8204522 , -0.01255853,  0.6345752 ,  1.2830219 , -0.76554227,\n",
       "       -0.43830413, -0.8321422 ,  0.5212836 , -0.4745319 ,  1.0762736 ,\n",
       "       -0.27273405,  0.49938437, -0.8178085 , -0.01171487,  0.6347916 ,\n",
       "        1.2827598 , -0.7630092 , -0.43644914, -0.8314895 ,  0.5212836 ,\n",
       "       -0.4534266 , -0.70706755, -0.28395075,  0.4762499 , -0.8240307 ,\n",
       "       -0.01253138,  0.63455904,  1.2830114 , -0.76319754, -0.43644914,\n",
       "       -0.83097875,  0.5212836 , -0.25697207, -1.0901561 , -0.3125736 ,\n",
       "        0.47137624, -0.8458948 , -0.01174044,  0.6348055 ,  1.2827688 ,\n",
       "       -0.76413864, -0.43830413, -0.82521826,  0.5212836 ,  0.05714545,\n",
       "       -0.5177691 , -0.34369314,  0.45299137, -0.8539893 , -0.01250719,\n",
       "        0.634547  ,  1.2830033 , -0.7653224 , -0.4401591 , -0.8296923 ,\n",
       "        0.5212836 ,  0.4181554 ,  1.2327095 , -0.33849683,  0.44931105,\n",
       "       -0.85031384, -0.01176341,  0.634816  ,  1.2827765 , -0.764968  ,\n",
       "       -0.43830413, -0.82349676,  0.5566924 ,  0.6362625 , -0.02168343,\n",
       "       -0.3267231 ,  0.44368178, -0.85477644, -0.0124853 ,  0.6345379 ,\n",
       "        1.2829958 , -0.76362234, -0.43830413, -0.8301274 ,  0.5566924 ,\n",
       "        0.57303965, -0.6371925 , -0.32338867,  0.46898264, -0.85175955,\n",
       "       -0.01178435,  0.6348239 ,  1.2827842 , -0.7652897 , -0.43830413,\n",
       "       -0.82793295,  0.5566924 ,  0.28138885,  0.40322828, -0.30505502,\n",
       "        0.4719966 , -0.8370618 , -0.0124652 ,  0.634531  ,  1.2829875 ,\n",
       "       -0.76695615, -0.43644914, -0.8329651 ,  0.5566924 , -0.04266188,\n",
       "        1.3000984 , -0.28888136,  0.4778443 , -0.8283142 , -0.01180371,\n",
       "        0.6348299 ,  1.2827933 , -0.76420265, -0.43459415, -0.83262455,\n",
       "        0.5212836 , -0.26524296, -0.25320202, -0.2780563 ,  0.47369117,\n",
       "       -0.8171119 , -0.01244651,  0.6345259 ,  1.2829773 , -0.7648157 ,\n",
       "       -0.43459415, -0.8272614 ,  0.5212836 , -0.3510638 , -0.94432205,\n",
       "       -0.27534586,  0.48324075, -0.815021  , -0.01182181,  0.6348343 ,\n",
       "        1.2828051 , -0.76401657, -0.43830413, -0.82515204,  0.5212836 ,\n",
       "       -0.43475595,  0.2850075 , -0.26228437,  0.48140854, -0.8056891 ,\n",
       "       -0.01242892,  0.63452214,  1.2829635 , -0.7666492 , -0.43644914,\n",
       "       -0.8302031 ,  0.5212836 , -0.4536596 ,  1.018211  , -0.2523645 ,\n",
       "        0.49015477, -0.8125921 , -0.01183895,  0.6348374 ,  1.2828217 ,\n",
       "       -0.7667169 , -0.43644914, -0.82719517,  0.5566924 , -0.42701632,\n",
       "       -0.9449892 , -0.30225363,  0.462603  , -0.83105844, -0.01241219,\n",
       "        0.6345196 ,  1.282943  , -0.76668596, -0.43644914, -0.82672226,\n",
       "        0.5566924 , -0.1738904 , -1.4646446 , -0.35826907,  0.44470733,\n",
       "       -0.87342876, -0.01185532,  0.6348394 ,  1.2828475 , -0.7666131 ,\n",
       "       -0.43644914, -0.8321043 ,  0.5566924 ,  0.31512627,  0.61234707,\n",
       "       -0.3623656 ,  0.435864  , -0.8582748 , -0.01239613,  0.634518  ,\n",
       "        1.282909  , -0.7654105 , -0.43644914, -0.82899237,  0.5566924 ,\n",
       "        0.6459701 ,  0.85276973, -0.30746108,  0.454385  , -0.83974946,\n",
       "       -0.01187111,  0.6348405 ,  1.2828946 , -0.76409656, -0.43459415,\n",
       "       -0.82851   ,  0.5212836 ,  0.67528033, -0.6214525 , -0.30438045,\n",
       "        0.45473152, -0.8367082 , -0.01238057,  0.6345174 ,  1.2828393 ,\n",
       "       -0.76790446, -0.43830413, -0.8242819 ,  0.5212836 ,  0.4798706 ,\n",
       "        0.04096306, -0.30865982,  0.4730173 , -0.83677673, -0.01188646,\n",
       "        0.6348407 ,  1.2830099 , -0.7643634 , -0.43459415, -0.8310071 ,\n",
       "        0.5212836 ,  0.23282643,  1.2476155 , -0.28360876,  0.4698998 ,\n",
       "       -0.8228449 , -0.01236539,  0.63451755,  1.2826065 , -0.76536465,\n",
       "       -0.43459415, -0.82884103,  0.5212836 , -0.07491679, -0.14783333,\n",
       "       -0.27319068,  0.47782546, -0.8167439 , -0.01190151,  0.6348402 ,\n",
       "        1.2837768 , -0.76520485, -0.43644914, -0.8274317 ,  0.5566924 ,\n",
       "       -0.35690835, -0.9104414 , -0.27549738,  0.47167012, -0.8248768 ,\n",
       "       -0.01235046,  0.6345185 ,  1.2864553 , -0.7651576 , -0.43644914,\n",
       "       -0.8270627 ,  0.5566924 , -0.5815991 ,  0.15969323, -0.27960086,\n",
       "        0.48504728, -0.82016593, -0.01191634,  0.6348388 ,  1.2818413 ,\n",
       "       -0.76463306, -0.43459415, -0.8305058 ,  0.5566924 , -0.5625746 ,\n",
       "        0.59290856, -0.29040384,  0.46106982, -0.8230167 , -0.0123357 ,\n",
       "        0.63452023,  1.2841964 , -0.7653957 , -0.43830413, -0.8301369 ,\n",
       "        0.5566924 , -0.28318918, -1.1680386 , -0.31099927,  0.45302543,\n",
       "       -0.8318728 , -0.01193105,  0.6348367 ,  1.2862347 , -0.76791096,\n",
       "       -0.43644914, -0.8320287 ,  0.5566924 ,  0.11031289, -0.59364974,\n",
       "       -0.3012466 ,  0.45010415, -0.8341355 , -0.01232101,  0.6345228 ,\n",
       "        1.2818147 , -0.7677069 , -0.43644914, -0.8262398 ,  0.5566924 ,\n",
       "        0.33524418,  1.2372242 , -0.30384725,  0.46845117, -0.8373691 ,\n",
       "       -0.01194573,  0.6348337 ,  1.2852632 , -0.76778495, -0.43644914,\n",
       "       -0.83243537,  0.5566924 ,  0.30914187,  0.5397552 , -0.2953327 ,\n",
       "        0.4531168 , -0.8264337 , -0.01230632,  0.63452625,  1.2852764 ,\n",
       "       -0.76606685, -0.43644914, -0.82835865,  0.5566924 ,  0.2313672 ,\n",
       "       -1.1158608 , -0.29275516,  0.45922357, -0.8316099 , -0.01196045,\n",
       "        0.6348298 ,  1.2820169 , -0.7663465 , -0.43644914, -0.83541495,\n",
       "        0.5566924 ,  0.10812496, -0.04453377, -0.30487835,  0.45537037,\n",
       "       -0.82472134, -0.01229156,  0.6345306 ,  1.2834704 , -0.7662891 ,\n",
       "       -0.43459415, -0.8260885 ,  0.5566924 ,  0.05822476,  1.3077123 ,\n",
       "       -0.29638216,  0.46894494, -0.8240668 , -0.01197527,  0.63482493,\n",
       "        1.2824252 , -0.7656115 , -0.43644914, -0.8338164 ,  0.5566924 ,\n",
       "        0.00962629,  0.07061943, -0.28126004,  0.46197784, -0.82115406,\n",
       "       -0.01227667,  0.634536  ,  1.283286  , -0.7659264 , -0.43644914,\n",
       "       -0.82973963,  0.5566924 , -0.12014635, -0.92634887, -0.27937442,\n",
       "        0.47714326, -0.826906  , -0.01199025,  0.6348189 ,  1.282531  ,\n",
       "       -0.7661284 , -0.43830413, -0.83432716,  0.5566924 , -0.28767002,\n",
       "        0.07942252, -0.28168064,  0.46896318, -0.82735133, -0.01226158,\n",
       "        0.6345427 ,  1.2832167 , -0.7651667 , -0.43644914, -0.8332962 ,\n",
       "        0.5566924 , -0.3336495 ,  0.6438629 , -0.28030097,  0.4702955 ,\n",
       "       -0.8165233 , -0.01200546,  0.6348116 ,  1.2825801 , -0.76499003,\n",
       "       -0.43644914, -0.83415693,  0.5566924 , -0.11205123, -0.7487416 ,\n",
       "       -0.30443925,  0.4452819 , -0.83581775, -0.01224623,  0.6345508 ,\n",
       "        1.28318   , -0.76527905, -0.43830413, -0.83668244,  0.5566924 ,\n",
       "        0.15072839, -0.9882911 , -0.32234037,  0.45112276, -0.84189606,\n",
       "       -0.01202095,  0.6348025 ,  1.2826089 , -0.76523805, -0.43830413,\n",
       "       -0.8330313 ,  0.5212836 ,  0.3783523 ,  0.8302835 , -0.30842692,\n",
       "        0.4451859 , -0.83436275, -0.01223058,  0.6345608 ,  1.2831566 ,\n",
       "       -0.7657358 , -0.43644914, -0.830695  ,  0.5212836 ,  0.47161886,\n",
       "        1.1435013 , -0.3109422 ,  0.46070942, -0.8267698 , -0.01203678,\n",
       "        0.63479143,  1.2826282 , -0.76491654, -0.43644914, -0.82835865,\n",
       "        0.5212836 ,  0.35065144, -0.5044136 , -0.27820113,  0.46460575,\n",
       "       -0.8202826 , -0.01221456,  0.63457316,  1.2831403 , -0.7674217 ,\n",
       "       -0.43830413, -0.83324885,  0.5212836 ,  0.11673872, -0.4607804 ,\n",
       "       -0.2701089 ,  0.48114523, -0.81017494, -0.01205301,  0.63477767,\n",
       "        1.2826424 , -0.7651366 , -0.43459415, -0.8313003 ,  0.5212836 ,\n",
       "       -0.16691414,  0.355453  , -0.2622311 ,  0.47060218, -0.81354856,\n",
       "       -0.01219812,  0.6345886 ,  1.2831279 , -0.76399165, -0.43644914,\n",
       "       -0.83532983,  0.5212836 , -0.35977715,  1.0023359 , -0.27537927,\n",
       "        0.47186038, -0.81428957, -0.01206968,  0.6347603 ,  1.2826535 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.iloc[922].pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32f932-8e0a-43e1-a293-bb2bba0a1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_nervous = [0.00653729, -0.18582821, -0.23318774, -0.2487897,  -0.23372887, -0.12444461, 0.00557272]\n",
    "\n",
    "excited_stressed = [-0.14335369, -0.2734212, -0.21269707, -0.26963243, -0.22057566, -0.07807975, -0.14732485]\n",
    "\n",
    "excited_inspired_happy = [-0.25548002, -0.29832116, -0.25125208, -0.28806356, -0.24982394,\n",
    "       -0.24082947, -0.2577177 ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
