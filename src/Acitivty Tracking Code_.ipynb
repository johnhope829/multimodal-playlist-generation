{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASET CLASS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grozz\\AppData\\Local\\Programs\\Microsoft VS Code\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'sleep': 0, 'sit-stand': 1, 'mixed': 2, 'walking': 3, 'vehicle': 4, 'bicycling': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\4070161790.py:38: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\4070161790.py:38: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\4070161790.py:38: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\4070161790.py:38: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\4070161790.py:38: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#sensor_df = pd.read_csv(\"P001.csv\")\n",
    "\n",
    "#labels_df = pd.read_csv(\"annotation-label-dictionary.csv\")\n",
    "\n",
    "labels_df = pd.read_csv(\"annotation-label-dictionary.csv\")\n",
    "\n",
    "# Pick one label scheme:\n",
    "chosen_column = \"label:Willetts2018\"\n",
    "\n",
    "# Map the string labels to integer classes\n",
    "label_mapping = {label: i for i, label in enumerate(labels_df[chosen_column].unique())}\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "subject_labels = labels_df[chosen_column].map(label_mapping).values\n",
    "\n",
    "\n",
    "sensor_folder = \"pids\"\n",
    "select_pids = [\"P001\", \"P002\", \"P003\", \"P004\", \"P005\"]\n",
    "\n",
    "\n",
    "# Convert labels to integers\n",
    "label_mapping = {label: i for i, label in enumerate(labels_df[chosen_column].unique())}\n",
    "mapped_labels = labels_df[chosen_column].map(label_mapping).values\n",
    "\n",
    "# Now split up the labels across subjects in `select_pids`\n",
    "data_list = []\n",
    "label_list = []\n",
    "\n",
    "offset = 0  # position in mapped_labels\n",
    "\n",
    "for pid in select_pids:\n",
    "    file_path = os.path.join(sensor_folder, f\"{pid}.csv\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        sensor_data = df[[\"x\", \"y\", \"z\"]].values\n",
    "        sensor_data = (sensor_data - sensor_data.mean(axis=0)) / sensor_data.std(axis=0)\n",
    "\n",
    "        n_samples = len(sensor_data)\n",
    "        labels = mapped_labels[offset:offset + n_samples]\n",
    "        offset += n_samples\n",
    "\n",
    "        data_list.append(sensor_data)\n",
    "        label_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\693305920.py:11: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\693305920.py:11: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\693305920.py:11: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\693305920.py:11: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\693305920.py:11: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "label_df = pd.read_csv(\"annotation-label-dictionary.csv\")\n",
    "chosen_column = \"label:Willetts2018\"\n",
    "annotation_to_label = dict(zip(label_df[\"annotation\"], label_df[chosen_column]))\n",
    "label_mapping = {label: i for i, label in enumerate(label_df[chosen_column].unique())}\n",
    "\n",
    "\n",
    "for pid in select_pids:\n",
    "    file_path = os.path.join(sensor_folder, f\"{pid}.csv\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Normalize sensor data\n",
    "        sensor_data = df[[\"x\", \"y\", \"z\"]].values\n",
    "        sensor_data = (sensor_data - sensor_data.mean(axis=0)) / sensor_data.std(axis=0)\n",
    "        data_list.append(sensor_data)\n",
    "\n",
    "        # Map annotation strings to class labels\n",
    "        annotations = df[\"annotation\"].map(annotation_to_label)\n",
    "        labels = annotations.map(label_mapping)\n",
    "        labels = labels.fillna(-1).astype(int).values  # -1 for unknown/missing labels\n",
    "        label_list.append(labels)\n",
    "        \n",
    "valid_indices = labels != -1\n",
    "sensor_data = sensor_data[valid_indices]\n",
    "labels = labels[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class Capture24Dataset(Dataset):\n",
    "    def __init__(self, data_list, label_list, window_size=256, stride=128):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for data, labels in zip(data_list, label_list):\n",
    "            for i in range(0, len(data) - window_size, stride):\n",
    "                window = data[i:i+window_size]\n",
    "                label_window = labels[i:i+window_size]\n",
    "                if len(label_window) == 0 or np.all(label_window == -1):\n",
    "                    continue  \n",
    "                if np.any(np.array(label_window) < 0):\n",
    "                    continue  \n",
    "                label = np.bincount(label_window).argmax()\n",
    "                self.X.append(window)\n",
    "                self.y.append(label)\n",
    "\n",
    "        self.X = torch.tensor(np.array(self.X), dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Capture24Dataset(data_list, label_list, window_size=256, stride=128)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class ActivityModel(nn.Module):\n",
    "    def __init__(self, input_channels=6, num_classes=6):\n",
    "        super(ActivityModel, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=32, hidden_size=64, batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # [B, T, C]\n",
    "        x = x.permute(0, 2, 1)  # → [B, C, T]\n",
    "        x = self.cnn(x)         # → [B, 32, T']\n",
    "        x = x.permute(0, 2, 1)  # → [B, T', 32]\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return self.classifier(h_n.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9630\n",
      "Epoch 2, Loss: 0.7489\n",
      "Epoch 3, Loss: 0.6694\n",
      "Epoch 4, Loss: 0.6093\n",
      "Epoch 5, Loss: 0.5541\n",
      "Epoch 6, Loss: 0.5243\n",
      "Epoch 7, Loss: 0.4989\n",
      "Epoch 8, Loss: 0.4782\n",
      "Epoch 9, Loss: 0.4644\n",
      "Epoch 10, Loss: 0.4529\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ActivityModel(input_channels=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    " \n",
    "for epoch in range(10): \n",
    "    model.train() \n",
    "    total_loss = 0 \n",
    "    for x_batch, y_batch in train_loader: \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device) \n",
    "        optimizer.zero_grad() \n",
    "        output = model(x_batch) \n",
    "        loss = criterion(output, y_batch) \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        total_loss += loss.item() \n",
    "     \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        labels = y_batch.numpy()\n",
    "\n",
    "        predictions.extend(preds)\n",
    "        actuals.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted\n",
      "0    walking    walking\n",
      "1      sleep      sleep\n",
      "2      sleep      sleep\n",
      "3    vehicle    vehicle\n",
      "4  bicycling  bicycling\n",
      "5      mixed      mixed\n",
      "6      sleep      sleep\n",
      "7  sit-stand  sit-stand\n",
      "8    walking  sit-stand\n",
      "9  sit-stand  sit-stand\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}  # To decode labels\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Actual\": [inv_label_mapping[a] for a in actuals],\n",
    "    \"Predicted\": [inv_label_mapping[p] for p in predictions]\n",
    "})\n",
    "\n",
    "print(results_df.head(10))  # Show first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8340\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(actuals, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Model with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'sleep': 0, 'sit-stand': 1, 'mixed': 2, 'walking': 3, 'vehicle': 4, 'bicycling': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\1044544365.py:25: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\1044544365.py:25: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\1044544365.py:25: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\1044544365.py:25: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\1044544365.py:25: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "label_mapping = {label: i for i, label in enumerate(labels_df[chosen_column].unique())}\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "subject_labels = labels_df[chosen_column].map(label_mapping).values\n",
    "\n",
    "\n",
    "sensor_folder = \"pids\"\n",
    "select_pids = [\"P006\", \"P007\", \"P008\", \"P009\", \"P010\"]\n",
    "\n",
    "\n",
    "# Convert labels to integers\n",
    "label_mapping = {label: i for i, label in enumerate(labels_df[chosen_column].unique())}\n",
    "mapped_labels = labels_df[chosen_column].map(label_mapping).values\n",
    "\n",
    "# Now split up the labels across subjects in `select_pids`\n",
    "data_list = []\n",
    "label_list = []\n",
    "\n",
    "offset = 0  # position in mapped_labels\n",
    "\n",
    "for pid in select_pids:\n",
    "    file_path = os.path.join(sensor_folder, f\"{pid}.csv\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        sensor_data = df[[\"x\", \"y\", \"z\"]].values\n",
    "        sensor_data = (sensor_data - sensor_data.mean(axis=0)) / sensor_data.std(axis=0)\n",
    "\n",
    "        n_samples = len(sensor_data)\n",
    "        labels = mapped_labels[offset:offset + n_samples]\n",
    "        offset += n_samples\n",
    "\n",
    "        data_list.append(sensor_data)\n",
    "        label_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\942780500.py:8: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\942780500.py:8: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\942780500.py:8: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\942780500.py:8: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\grozz\\AppData\\Local\\Temp\\ipykernel_25356\\942780500.py:8: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "label_list = []\n",
    "data_list = []\n",
    "label_df = pd.read_csv(\"annotation-label-dictionary.csv\")   \n",
    "for pid in select_pids:\n",
    "    file_path = os.path.join(sensor_folder, f\"{pid}.csv\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        sensor_data = df[[\"x\", \"y\", \"z\"]].values\n",
    "        sensor_data = (sensor_data - sensor_data.mean(axis=0)) / sensor_data.std(axis=0)\n",
    "\n",
    "        # Map annotation strings to class labels\n",
    "        annotations = df[\"annotation\"].map(annotation_to_label)\n",
    "        labels = annotations.map(label_mapping)\n",
    "        labels = labels.fillna(-1).astype(int).values\n",
    "\n",
    "        # Filter out invalid labels BEFORE appending\n",
    "        valid_indices = labels != -1\n",
    "        sensor_data = sensor_data[valid_indices]\n",
    "        labels = labels[valid_indices]\n",
    "\n",
    "        if len(sensor_data) >= 256:\n",
    "            data_list.append(sensor_data)\n",
    "            label_list.append(labels)\n",
    "        else:\n",
    "            print(f\"{pid} skipped — not enough valid data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Capture24Dataset(data_list, label_list, window_size=256, stride=128)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7935\n",
      "Epoch 2, Loss: 0.5448\n",
      "Epoch 3, Loss: 0.4676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ActivityModel(input_channels=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    " \n",
    "for epoch in range(10): \n",
    "    model.train() \n",
    "    total_loss = 0 \n",
    "    for x_batch, y_batch in train_loader: \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device) \n",
    "        optimizer.zero_grad() \n",
    "        output = model(x_batch) \n",
    "        loss = criterion(output, y_batch) \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        total_loss += loss.item() \n",
    "     \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemcordelli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
